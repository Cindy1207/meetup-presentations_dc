---
title: "Two Quick Applications of the rvest Package for R-Ladies DC Open Data Day"
output: html_notebook
author: "Kelly O'Briant & R-Ladies DC"
---

### 1. Single Table Scraping - Wikipedia Female Nobel Laureates Example
One of the best places to start experimenting with rvest is Wikipedia and one of the easiest ways to start learning how package functions work is to take code someone else has writen and try to make it work for an example of your choosing. 

Wikipedia is great because it has "List Articles" which have data already displayed in table form (very nice of them).

I often use [Rbloggers.com](https://www.r-bloggers.com/) to search for tutorials on packages or concepts I've never tried before. I can usually find a little bit of code or insight just to get me started. Very rarely will I find some solution that works just through copy/paste. But it sends me down a path (maybe not even the right path at first) that I can use to learn some new things. Here is an R Bloggers Article I found for getting started with rvest called, [Web scraping with rvest: So easy, even an MBA can do it!](https://www.r-bloggers.com/webscraping-with-rvest-so-easy-even-an-mba-can-do-it/)

I thought this would be a good place to start, so I tested the code out using the List of Female Nobel Laureates page.

```{r}
library(rvest)
library(dplyr)

url <- "https://en.wikipedia.org/wiki/List_of_female_Nobel_laureates"
page <- read_html(url)
nobel_ladies <- page %>%
  html_nodes("table") %>%
  .[1] %>%
  html_table()

nobel_ladies <- nobel_ladies[[1]]
head(nobel_ladies)
```


#### Oh no! This is not the table I wanted!
How did this happen? I'll need to look at the code I used, and also go back to [inspect the source page.](https://en.wikipedia.org/wiki/List_of_female_Nobel_laureates)

It appears that the code snippet above is pulling the first "table" element it finds off the page. Perhaps the first table isn't the one we want? Let's try to grab the second table:

```{r}
nobel_ladies <- page %>%
  html_nodes("table") %>%
  .[2] %>%
  html_table()

nobel_ladies <- nobel_ladies[[1]]
head(nobel_ladies)
```


#### Yes! This looks much better.

Now we've scraped our first Wikipedia table! Awesome :) We're well on our way to creating an entire data package called "Winning Ladies!"

--------------------

### 2. Multi-Table Scraping - Judo Competition Results Example

I'm interested in getting some [Judo competition results data](http://www.judoinside.com/event/11513/2017_Pan_American_Open_Santiago) into R using rvest. Let's use the code we started with in the first example and see if it can be applied to this situation.

In this case, I know there are 14 discrete tables I want to pull in from judoinside.com, so I'll change the table reference number to include 1-14:
```{r}
url <- "http://www.judoinside.com/event/11513/2017_Pan_American_Open_Santiago"
page <- read_html(url)
judo_results <- page %>%
  html_nodes("table") %>%
  .[1:14] %>%
  html_table()

summary(judo_results)
```


#### Cool! It looks like I got a list of 14 data frames, now what?

Let's look at the first one and see if we like it:

```{r}
judo_results1 <- judo_results[[1]]
print(judo_results1)
```


#### The data looks mostly right, but I see some things I'd like to correct.

##### Problem 1: The column names are not descriptive
I'd like to change the column names for each of the 14 tables so that they read:
- Placement_(WeightClass)
- Judoka_Name
- Country

We could do this to each table, one at a time like this: 
`names(judo_results1) <- c('Placement_U60', 'Judoka_Name', 'Country')`
But that's annoying. So instead, let's leverage the plyr package to apply a rename to all the tables at once!

We'll inspect a data frame from the middle to check out the change:
```{r}
library(plyr)
labeled_judo <- llply(judo_results, function(df) {
  names(df) <- c(paste("Placement_",df[1,1],sep=''),'Judoka_Name', 'Country')
  return(df)
})

#Inspect a data frame from the middle to check out the change:
labeled_judo[[9]]
```


##### Problem 2: The first row of each table needs to be removed
Yes, we could have tackled this issue in the same llply function we used previously, but for the sake of taking things one step at a time, let's use plyr again!

We'll check to make sure the first row of data frame 9 has data instead of weight class headers:
```{r}
labeled_judo <- llply(labeled_judo, function(df) {
  df <- df[-1,]
  return(df)
})

# Check to make sure the first row of data frame 9 has data instead of weight class headers:
labeled_judo[[9]][1,]
```


#### Awesome, but what do I do with a list of data frames?
For the purposes of publishing and sharing, I don't like the idea of trying to turn this list of data frames into a CSV file. To me, it looks more like JSON - so is there a way to turn it into an exportable JSON file?

```{r}
library(jsonlite)
json_judo <- toJSON(labeled_judo, dataframe = "rows")
prettify(json_judo)

write(json_judo, file="pan_am_judo.JSON")
```


#### How would I get this JSON data file back into a list of data frames?

```{r}
library(jsonlite)
reverse_judo <- read_json(path = 'pan_am_judo.JSON', simplifyVector = TRUE)
```

